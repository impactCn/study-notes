# 第一章：缓存为王
### 1.1 什么是缓存  
#### 按软件系统所在位置的不同
1. 客户端的缓存
2. 服务端缓存
3. 网络中的缓存
#### 按规模和部署的方式
1. 单体缓存
2. 缓存集群
3. 分布式缓存
### 1.2 为什么使用缓存？
提高数据的读取，给用户带来良好的体验
#### 1.2.1 从用户的体验来说
系统性能是一种非功能特性，它关注的不是某种特定的功能，而是完成该功能时所展示出来的及时性。
#### 1.2.2 关于系统的性能
系统性能的通常指标
1. 响应时间：该软件系统所有功能的平均响应时间或者所有功能中最大响应时间
2. 延迟时间：系统实际处理请求所需时间
3. 吞吐量：单位时间内处理请求的数量
4. 并发用户数：同时承载的正常使用系统功能的用户数量
5. 资源利用率：一段时间内资源平均被占用的情况
### 1.3 从网站的架构发展看缓存
开始：开始还没什么访问量，在一台服务器上部署（LAMP）。  
然后：渐渐有访问量，系统压力变大，数据与应用开始分离，变成两台机器。  
接着：访问网站的人数据越来越多，开始采取缓存策略。比如缓存静态页面、热点数据预先缓存。  
之后：随着访问量的持续增加，开始增加Web服务器，开始使用缓存同步机制以及共享文件或者共享存储。  
再后来：访问量高速增长，开始数据库的调优、优化数据库自身缓存、采取数据库集群以及分库分表，可能发现之前同步方案出现问题，因为数据量太大了，可能开始运用分布式缓存。  
最后：系统进入无级的大型网站阶段，当网站流量增加的时候，应对的解决方案就是不断添加Web服务器、数据库服务器、缓存服务器。
### 1.4 客户端缓存
1. 页面缓存
2. 浏览器缓存
3. 移动互联网而言，APP缓存自身所使用的缓存。
#### 1.4.1 页面缓存
前端使用H5本地缓存页面
#### 1.4.2 浏览器缓存
根据服务器约定的规则进行工作，工作规则也很简单：检查已确保副本是最新的，通常只要一次会话。浏览器会在硬盘上专门开辟一个空间来存储资源副本作为缓存。
#### 1.4.3 APP上的缓存
1. 某些界面使用文件缓存方法
2. 使用数据库缓存方法
### 1.5 网络中的缓存
网络中的缓存位于客户端和服务端之间，代理或者响应客户端的网络，从而对重复的请求返回缓存中数据源。
#### 1.5.1 Web代理缓存
浏览器不是直接到Web服务器去取会页面而是向Web代理发出请求，由代理服务器来取浏览器所需要的信息并发送给浏览器。而且，Web代理缓存有很大的空间，不断将获取的数据储存到本地存储器上，如果是缓存存在且是最新的，那么就不用重新从Web服务器取数据，而是直接将缓存给用户的浏览器。
#### 1.5.2 边缘缓存
代理缓存可以缓存原始资源服务器的资源，而不是每次都要向原始资源服务器请求数据。  
经典例子：CDN边缘节点
### 1.6 服务端缓存
服务端缓存是系统性能的重中之重，其中数据库是整个系统中的瓶颈，
#### 1.6.1 数据库缓存
1. 查询缓存
2. 检查Query Cache的合理性
3. InnoDB 的缓存性能
#### 1.6.2 平台级缓存
以Ehcache为例：  
**轻量快速：** Ehcache的线程机制是为大型高并发系统设计的。  
**良好伸缩：** 数据可以伸缩到数G字节，节点可以到数百个。  
**简介灵活：** 运行时缓存配置，存活时间、空间时间、内存和磁盘放混村的最大数据等是可以运行时时候修改。 
**标准支持：** Ehcache提供了对JSR107 JCahe API最完整的实现。  
**强扩展性：** 节点发现，冗余器和监听器都可以插件化。  
**数据持久：** 缓存的数据可以在机器重新启动后从磁盘上重新获得。  
**缓存监听：** 提供了许多对缓存事件发生后的处理机制。  
**分布式缓存：** 支持高性能缓存，兼具灵活和扩展性。
#### 1.6.3 应用级缓存
当平台级缓存不能满足系统性能要求的时候，就要开始考虑使用应用级缓存了。主要是NoSQL。  
1. redis
2. MongoDB  
3. Memcached  

**缓存术语如下**  
**缓存命中：** 当用户发起一个请求时，系统接收到这个请求。如果该请求的数据是在缓存中，这一数据就会被使用。  
**没有命中：** 如果缓存中还有存储空间，那么没有命中的数据对象会被储存到缓存中。  
**储存成本：** 当没有缓存命中时，系统会从数据库或者其他数据源取出数据，然后放入缓存，而把这个数据放入缓存所需要的时间和空间，就是存储成本。  
**缓存失败：** 当存储在缓存中的数据需要更新时，就意味着这一数据缓存失效了。  
**替代策略：** 当缓存没有命中，并且缓存容量已经满了，就需要在缓存中除去一个旧数据，然后加入一条新缓存，而到底应该出去哪些旧数据，就是替代策略决定的。  
目前主流策略：  
1. Least-Recently-Used(LRU):  
替换掉最近被请求最少的对象，然而在直接应用与代理缓存中效果欠佳，因为Web访问时间常常变换很大。
2. Least-Frequently-Used(LFU):  
替换掉访问次数最少的缓存，这一策略意图是保存最常用的、最流行的对象。然而有些文档可能有很高的使用率，但之后再也不会利用。传统的LFR策略没有提供任何一处这类文件的机制，因此会导致“缓存污染”，即一个先前流行的缓存对象会在缓存中驻留很长时间，这样，就是阻碍新进来的可能会流行的对象对它的代替。 
3. Least Recently Used 2 (LRU2):  
LRU的变种，把被访问两次的对象放入缓存池，当缓存池满的时候，就会把两次最少使用的对象移除，因为只需要访问对象两次，访问负载就会随着缓存池的增加而增加。 
4. Two Queues (2Q):  
Two Queues是LRU的另一种变种，把被访问的数据放到LRU的缓存之后，如果这个对象再一次被访问，就把他转移到第二个、更大的LRU缓存，使用了多级缓存的方式。去除缓存对象是为了保持第一个缓存池是第二个缓存池的1/3。当缓存的访问负载是固定的时候，把LRU换成LRU2，就比增加缓存的容量更好。 
5. SIZE:  
替换占用空间最大的对象，这一策略通过淘汰一个大对象而不是多个小对象来提高命中率。不过，可能有些进入缓存的小对象永远不会被访问。SIZE策略没有提供淘汰这类对象的机制，也会导致“缓存污染”。  
6. LRU-Threshold  
不缓存超过某一个siez对象，其他和LRU相同。  
7. Log(Size)+LRU:  
替换size最大的对象，当size相同时，按LRU进行替换。  
8. First in First out (FIFO):  
FIFO通过一个队列去跟踪所有缓存对象，最近最常用的缓存对象放在后面，而更早的缓存对象放在前面，当缓存容量满的时候，排在前面的缓存对象就会被踢走，然后把心的缓存对象加进去。
# 第二章：分布式系统理论
## 2.1 分布式系统概论
**分布式程序设计语言：** 基础结构。  
**理论基础：** 全局状态和时间排序；逻辑时钟和物理时钟。  
**分布式操作系统：** 互斥和选举；死锁的检测和解决方法；自稳定；任务调度和负载平衡；  
**分布式通讯：** 一对一通讯；组通讯；  
**可靠性：** 一致性；错误恢复；可靠通讯；  
**分布式数据管理：** 复制数据的一致性；分布式并发控制；  
**应用：** 分布式操作系统；分布式文件系统；分布式数据库系统；分布式共享存储器；异型处理。  
## 2.2 分布式系统概念
### 2.2.1 进程与线程
**进程：** 具有一定独立功能的程序关于某个数据集合的一次运行活动，是系统进行资源分配和调度的一个独立单位。  
**线程：** 是进程的一个实体，它比进程更小的能独立运行的基本单位，不拥有系统资源，只拥有在运行中必不可缺的资源。  
### 2.2.2 并发
并发指的是，系统只能将CPU运行的时间切分成多个时间段，再将时间段分配给各个线程执行，在一个时间段运行的线程代码时，其他线程则处于被挂起状态。
### 2.2.3 锁
锁：用于保护临时区的一种机制，主要被用在多线程中。  
减少或规避锁竞争的策略有如下：  
1. 分拆锁
2. 分离锁
3. 避免共享缓存
4. 使用并发容器如Amino
5. 使用Immutable数据和ThreadLocal中的数据
### 2.2.4 并行
并发：当一个CPU执行一个线程时，另一个CPU可以执行另一个线程，两个线程互不抢占CPU资源。
| 名称 |  表现  |
|------|--------|
| 并发 |  两个或多个事件在同一时间间隔内发生  |
| 并行 |  两个或者多个时间在同一时刻发生      |
### 2.2.5 集群
集群是一组相互独立的、通过高速网络互联的计算机。  
系统组成如下：  
**节点：** 系统中按照协议完成计算工作的一个逻辑实体，可能是执行某些工作的进程或机器。  
**网络：** 系统的数据传输通道，用来彼此通信。通信具有方向性。  
**存储：** 系统中持久化数据的数据库文件存储。  
集群体系结构的关键四个层次：  
**网络层：** 网络互联结构、通讯协议、信号协议等。   
节点机及操作系统是高性能客户机，分层或基于微内核的操作系统等。  
**集群系统管理层：** 资源管理、资源调度、负载平衡、并行IPO、安全等。  
**应用层：** 并发程序开发环境、串行应用、并发应用等。
### 2.2.6 状态特性
服务无状态，易于扩展
### 2.2.7 系统重发与幂等性
**网络重发：** 当APP1与servierB的链路出现网络异常的时候，用户得到的操作失败的反馈。  
**幂等性：** 调用1次和N次要返回的结果都一样。 
### 2.2.8 硬件异常
1. 服务器宕机
2. 网络异常
3. 磁盘异常
4. 机房级异常
## 2.3 分布式理论
**一致性解决方案：** Paxos、Raft、2PC、3PC算法  
**网络堵塞方案：** Lease机制  
**存储一致性方案：** MVCC、Quorum NWR  
### 2.3.1 CAP理论
**一致性（C）：** 在分布式系统中的所有数据备份，在同一时刻是否有相同的值。  
**可用性（A）：** 在集群一部分节点故障时，集群整体是否还能响应客户端的读写请求。  
**分区容忍性（P）：** 以实际效果而言，分区相当于对通信的时限要求。系统如果不能在一定时限内达成数据一致性。就意味着发生分区行为，必须就当前操作在C和A之间做出选择。  
三者不可共存，分以下情况：  
1. CA without p: 没有（P）网络异常的时候，即分区行为，单独的数据库，保证一致性(A)，同时多个应用服务器，保证各个节点都正常，从而保证了高可用性(C)。
2. CP without A：当发生网络异常的时候，产生分区情况(P)，要求数据强一致性(C)，这其他节点服务等待网络修复，能才达到数据一致性(C)，这时候不能立马提供服务，所以分布式系统没有了高可用(A).
3. AP without C：有分区的情况的时候(P)，节点之间可能失去联系，为了高可用(A)，每个节点都是由本地数据提供服务，这样会导致全局数据不一致。
### 2.3.3 Paxos
是一种基于消息传递的一致性算法。  
1. Paxos是什么  
Paxos协议是一种解决分布式系统中，多个节点之间就某个值(提案)达成一致性(决议)的通信系统。它能够处理在少数节点离线的情况下，剩余的多数节点仍然能够达成一致。
2. Paxos协议简介  
是两阶段协议，分为Prepare阶段和Accept阶段，该协议涉及两个角色，Proposer和Accepter。其中，Proposer是提议提案的服务器，而Acceptor是批准提案的服务器。二者在物理上可以是同一台机器。   
* **Prepare阶段(1)：Proposer发送给Prepare** 
    * Proposer生成全局唯一的ID，无需携带内容提案。Id记作Pn  
* **Prepare阶段(2)：Acceptor应答Prepare**
    * Acceptor收到提案请求后，做出以下约定：  
    1）不再应答<=Pn的Prepare请求。  
    2）对于<Pn的Accept请求亦不处理。
    * Acceptor做的处理包括：  
    1）应答前要在本地持久化当前提案。
    2）如果当前提案的Id大于此前存放的Id，则替代此前的Id.
* **Accept阶段(1)：Proposer发送Accept**
    * Proposer收到多数派的应答后，随意决定提案内容，然后携带当前Id，想Paxos集群的所有机器发送Accept请求。
* **Accept阶段(2)：Acceptor应答Accept**
    * Acceptor收到请求后，在不违背自己之前做的约定，持久化当前的Id和提案内容。最后Proposer收集到多数派的应答的Accept回复后，形成决议。
### 2.3.4 2PC
两阶段提交协议（2PC）是典型的原子提交协议（atomic commmitment protocol）。它是一种由协调器来处理分布式原子参与者是提交或者回滚事务的分布式事务。
* **提交请求阶段或者叫投票阶段：**  
该阶段阶段的任务是确定相关参与者对于事务处理是否准备就绪，YES代表可以commit，NO反之。  
比如：  
    + 协调器会分别向多个事务参与者，发出是否请求commit的动作，事务参与者进行回调，如果都做出了YES的请求，则可以进行commit的动作，如果里面有一个做出了NO的请求，怎么协调器不进行commit的决策。 
* **提交阶段：**  
基于投票结果，由协调器决定提交事务抑或是退出事务处理；各事务参与者遵循指示，对本地事务资源做需要工作。  
比如：
    + 协调器向多个事务者发出提交(commit)指令，多个事务者参与执行提交执行并确定消息给协调器，如果里面有个事务者提交失败或者超时，则通知协调器，发起回滚。   
* **2PC的确定：**
    + 阻塞协议：如果协调器宕机，某些参与者无法解决他们的事务，而处于被挂起状态。
    + 复杂程度高：每个阶段都有协调器分别与多个事务参与者应答

### 2.3.5 3PC
在2PC的基础上加多一个交互，也就是预提交。解决了即使协调器在下一阶段不可用，或者调用超时，也算提交成功。

### 2.3.6 Raft
Raft提供了和Raxos算法相同的功能和性能，但是他的算法结构和Paxos不同。Raft算法更加容易理解并且更容易构建实际的系统，为了提升可理解性

### 2.4.2 高可用设计
* 主备模式：当主机宕机的时候，备机接管主机的一切。

* 互备模式：一个系统存在有个多master，每个master都具有全套服务能力。而数据库之间需要通过同步保障一致性。

* 集群模式：

### 2.4.3 容错性
指：IT系统对于错误包容的能力。

### 2.4.4 负载均衡
负载均衡：使用多台集群服务器共同分担计算任务，把网络请求以及计算分配到集群可用服务器上去，从而达到可用性及较好的用户操作体验。

## 2.5 分布式系统设计实践
解决通用性问题：  
1. 全局Id生成
2. 哈希取模分配  
3. 路由表
4. 一致性哈希
5. 数据拆分

### 2.5.1 全局Id生成
* UUID  
  * 优点：API简单、易用
  * 缺点：占用空间、字符串本身无法加工、可读性不强。

* ID生成表模式  
  * 优点：简单易用
  * 使用了mysql数据库独特语法REPLACE INTO

* SnowFlake
  * 优点：高性能、低延迟、独立的应用、按时间有序
  * 缺点：需要独立的开发和部署




    






























